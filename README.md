# AI-Powered Product Recommendation Engine
## Intelligent eCommerce Recommendations with GPT-3.5-turbo

### Overview

This project is an AI-powered product recommendation system that provides personalized suggestions based on user preferences and browsing history. Using OpenAI's GPT-3.5-turbo, the system leverages advanced prompt engineering to generate relevant recommendations along with detailed reasoning for each suggestion.

The system demonstrates full-stack development skills, including backend API creation, LLM integration, and a responsive React frontend. This project showcases the integration of modern AI capabilities into practical eCommerce applications.

### Project Architecture

```
project-root/
│
├── backend/
│   ├── app.py               # Main Flask API server
│   ├── requirements.txt     # Python dependencies
│   ├── config.py            # Environment variables (API key)
│   ├── data/products.json   # Sample product catalog
│   ├── services/
│   │   ├── llm_service.py   # LLM interactions with OpenAI
│   │   └── product_service.py # Product operations and filtering
│   └── README.md            # Backend setup instructions
│
├── frontend/
│   ├── public/index.html
│   ├── src/
│   │   ├── App.js           # Main React application
│   │   ├── index.js         # Application entry point
│   │   ├── components/
│   │   │   ├── Catalog.js       # Product catalog display
│   │   │   ├── UserPreferences.js # User preference form
│   │   │   ├── Recommendations.js # AI recommendations display
│   │   │   └── BrowsingHistory.js # Browsing history component
│   │   ├── services/api.js  # API client for backend communication
│   │   └── styles/App.css   # Application styling
│   ├── package.json         # NPM dependencies
│   └── README.md            # Frontend setup guide
│
└── README.md                # This file
```

### Setup Instructions

#### Backend Setup

1. **Navigate to the backend directory**
   ```bash
   cd backend
   ```

2. **Create and activate a virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate   # Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set your OpenAI API key**
   
   Option A - Environment variable:
   ```bash
   export OPENAI_API_KEY=<YOUR_API_KEY>
   ```
   
   Option B - Update `config.py`:
   ```python
   OPENAI_API_KEY = "your_api_key_here"
   ```

5. **Run the Flask server**
   ```bash
   python app.py
   ```
   
   The backend will run on `http://localhost:5000`

#### Frontend Setup

1. **Navigate to the frontend directory**
   ```bash
   cd frontend
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Start the development server**
   ```bash
   npm start
   ```
   
   The application will open at `http://localhost:3000`

### Usage Instructions

#### 1. Select Preferences
Users can choose product categories, brands, and price ranges via the preference form to personalize their experience.

#### 2. Browse Products
Clicking on products in the catalog adds them to browsing history, which the AI uses to understand user interests.

#### 3. View Recommendations
Personalized recommendations are displayed with explanations generated by GPT-3.5-turbo, based on your preferences and browsing history.

### Prompt Engineering

#### Objective
Ensure the LLM recommends exactly 5 products that match user preferences while providing clear reasoning for each recommendation.

#### Strategy
- **Context Inclusion**: Include user preferences and browsing history in the prompt
- **Structured Output**: Provide a clear JSON schema for output: `{product_id, explanation, score}`
- **Token Optimization**: Limit context to top 50 products to optimize token usage and manage costs

#### Example Prompt Structure
```
You are an expert eCommerce recommendation assistant.

Recommend exactly 5 products based on user preferences:
- categories: ["Electronics", "Footwear"]
- brands: ["BrandA", "BrandB"]
- price_range: [50, 200]

Browsing history: [Recent product interactions]

Include explanations and return ONLY a JSON array with the format:
[{"product_id": "...", "explanation": "...", "score": 0.95}]
```

### Challenges & Solutions

| Challenge | Solution |
|-----------|----------|
| Handling large product catalogs | Limited prompt context to top 50 products to avoid token overflow |
| Ensuring consistent JSON output from LLM | Added strict JSON schema in prompt and fallback error handling |
| Real-time recommendation updates | Implemented frontend state management with React hooks to instantly reflect preference changes |
| Managing API costs | Implemented token optimization and caching strategies |

### Development Timeline

| Component | Time Spent |
|-----------|------------|
| Backend API & LLM Integration | 15 hours |
| Frontend Components & React State Management | 12 hours |
| Prompt Engineering & Testing | 8 hours |
| Documentation & Repository Setup | 3 hours |
| **Total Development Time** | **~38 hours** |

### API Endpoints

#### GET `/api/products`
Retrieve all available products from the catalog.

#### POST `/api/recommendations`
Generate AI-powered recommendations based on user data.

**Request Body:**
```json
{
  "preferences": {
    "categories": ["Electronics", "Footwear"],
    "brands": ["Apple", "Samsung"],
    "price_range": [100, 500]
  },
  "browsing_history": ["product_id_1", "product_id_2"]
}
```

**Response:**
```json
[
  {
    "product_id": "product123",
    "explanation": "Based on your interest in electronics and Samsung brand preference...",
    "score": 0.95
  }
]
```

### Future Improvements

#### Phase 1: Enhanced Functionality
- **User Authentication**: Add user authentication and persistent profiles
- **Performance Optimization**: Implement LLM caching for faster response times
- **Advanced Filtering**: Add filtering, sorting, and search capabilities

#### Phase 2: Production Features
- **A/B Testing**: Compare different recommendation algorithms and prompt strategies
- **Analytics Integration**: Track recommendation performance and user engagement
- **Database Integration**: Move from JSON files to proper database storage

#### Phase 3: Scalability
- **Unit Testing**: Add comprehensive unit and integration tests for backend and frontend
- **Monitoring**: Implement logging and performance monitoring
- **Microservices**: Consider microservices architecture for larger scale deployment

### Deployment

#### Frontend Deployment (Netlify)
1. Build the production bundle: `npm run build`
2. Deploy the `build` folder to Netlify
3. Update API base URLs to point to production backend

#### Backend Deployment (Heroku)
1. Create a `Procfile` with: `web: python app.py`
2. Set environment variables in Heroku dashboard
3. Deploy using Git or Heroku CLI

Optional deployment can be done using Netlify (frontend) and Heroku (backend). Include deployed URLs in your repository README if available.

### Important Notes

- **Security**: Do not commit your OpenAI API key; always use environment variables
- **Code Quality**: Ensure clean code, modular structure, and proper error handling
- **User Experience**: The system is designed to be responsive and intuitive, with a focus on user experience
- **Performance**: Monitor API usage to manage costs and implement appropriate rate limiting

### Technical Stack

- **Backend**: Python, Flask, OpenAI API
- **Frontend**: React, JavaScript, CSS
- **AI Integration**: GPT-3.5-turbo for recommendation generation
- **Data Format**: JSON for product catalog and API communication

### Getting Started

1. Clone this repository
2. Follow the backend setup instructions above
3. Follow the frontend setup instructions above
4. Configure your OpenAI API key
5. Start both servers and begin testing the recommendation system

The system will provide intelligent, personalized product recommendations that adapt to user preferences and browsing behavior in real-time.

---

**This project demonstrates the practical application of LLMs in eCommerce recommendation systems, showcasing prompt engineering, full-stack development, and AI integration skills.**
